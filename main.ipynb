{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6705, 128, 130) (6705, 14)\n",
      "(6705, 128, 130) (6705, 12)\n"
     ]
    }
   ],
   "source": [
    "data_train = pd.read_csv('dataset_train.csv')\n",
    "data_test = pd.read_csv('dataset_test.csv')\n",
    "\n",
    "data_test_folder = \"./IRMAS-TestingData/\" \n",
    "\n",
    "def getdParam():\n",
    "    dList = []\n",
    "    for filename in data_train['name']:\n",
    "        path = os.path.join(data_test_folder, filename + \".wav\")\n",
    "        audio, sr = librosa.load(path)\n",
    "        dList.append(librosa.get_duration(y=audio, sr=sr))\n",
    "    return dList\n",
    "\n",
    "dmin = 5.019773242630386 # La fonction prend 1min30 à s'executer, on a donc sauvegardé le résultat dans une variable\n",
    "dmean = 16.886306332321844 \n",
    "dmax = 20.0\n",
    "len = 2874\n",
    "\n",
    "def getSpectre():\n",
    "    L = []\n",
    "\n",
    "    for path in data_train['path']:\n",
    "        audio, sr = librosa.load(path)\n",
    "        spectre = librosa.feature.melspectrogram(y = audio, sr = sr, n_mels = 128, fmax = 8000)\n",
    "        ptodb = librosa.power_to_db(spectre, ref=np.max)\n",
    "        L.append(ptodb)\n",
    "        \n",
    "    list_spectres = np.array(L)\n",
    "    np.save('list_spectres.npy', list_spectres)\n",
    "    return list_spectres\n",
    "\n",
    "#list_spectres = getSpectre() ##La fonction prend très longtemps à créer le fichier npy, on l'execute une fois et on enregistre le fichier\n",
    "list_spectres = np.load('list_spectres.npy')\n",
    "print(list_spectres.shape, data_train.shape)\n",
    "\n",
    "x_train = list_spectres\n",
    "colonnes_y = [\"cel\", \"cla\", \"flu\", \"gac\", \"gel\", \"org\", \"pia\", \"sax\", \"tru\", \"vio\", \"voi\", \"drum\"]\n",
    "y_train = data_train[colonnes_y].values\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_2 (Flatten)         (None, 16640)             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                1065024   \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 12)                780       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,065,804\n",
      "Trainable params: 1,065,804\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "210/210 [==============================] - 7s 27ms/step - loss: 32.2416 - accuracy: 0.1776\n",
      "Epoch 2/5\n",
      "210/210 [==============================] - 4s 19ms/step - loss: 3.3137 - accuracy: 0.2550\n",
      "Epoch 3/5\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 3.2881 - accuracy: 0.2550\n",
      "Epoch 4/5\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 3.2678 - accuracy: 0.2550\n",
      "Epoch 5/5\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 3.2525 - accuracy: 0.2550\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21d033cbc40>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.Input(shape=(128, 130)),  # Input layer with shape (128, 120)\n",
    "    layers.Flatten(),                # Flatten the input into a 1D array\n",
    "    layers.Dense(64, activation='relu'),   # Dense layer with 64 units and ReLU activation\n",
    "    layers.Dense(12, activation='softmax')  # Output layer with 12 units and softmax activation\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=5)\n",
    "\n",
    "#loss, accuracy = model.evaluate(x_test, y_test)\n",
    "#print(\"Test loss:\", loss)\n",
    "#print(\"Test accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
